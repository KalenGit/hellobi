{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[4]\") \\\n",
    "   .appName(\"test\") \\\n",
    "   .enableHiveSupport() \\\n",
    "   .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Apache Web Server Log file format\n",
    "\n",
    "今天要使用 Apache Common Log Format(CLF)．每一條Log 長得像這樣\n",
    "\n",
    "`127.0.0.1 - - [01/Aug/1995:00:00:01 -0400] \"GET /images/launch-logo.gif HTTP/1.0\" 200 1839`\n",
    "\n",
    "每個部分的說明如下:\n",
    "\n",
    "`127.0.0.1` Client 的 ip 位置．\n",
    "\n",
    "`[01/Aug/1995:00:00:01 -0400]` 請求發生的時間. 格式為: [day/month/year:hour:minute:second timezone]\n",
    "\n",
    "  - #### day = 2 digits\n",
    "  - #### month = 3 letters\n",
    "  - #### year = 4 digits\n",
    "  - #### hour = 2 digits\n",
    "  - #### minute = 2 digits\n",
    "  - #### second = 2 digits\n",
    "  - #### zone = (+ | -) 4 digits\n",
    "  \n",
    "`\"GET /images/launch-logo.gif HTTP/1.0\"` 請求的第一行\n",
    "\n",
    "`200` 此次請求的狀態碼\n",
    "\n",
    "`1839` 傳回 Clinet 端的物件大小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NASA-HTTP Web Server Log\n",
    "\n",
    "資料將使用 NASA Kennedy Space Center 的網站 Server 資料．這是一個公開資料可以在http://ita.ee.lbl.gov/html/contrib/NASA-HTTP.html 找到．\n",
    "\n",
    "或是你也可以直接從這裡下載 ftp://ita.ee.lbl.gov/traces/NASA_access_log_Jul95.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 下載資料需要解壓縮並放到 HDFS\n",
    "\n",
    "```bash\n",
    "gunzip NASA_access_log_Jul95.gz\n",
    "hadoop fs -put NASA_access_log_Jul95 /tmp\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Parsing Each Log Line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import datetime\n",
    "\n",
    "from pyspark.sql import Row\n",
    "\n",
    "month_map = {'Jan': 1, 'Feb': 2, 'Mar':3, 'Apr':4, 'May':5, 'Jun':6, 'Jul':7,\n",
    "    'Aug':8,  'Sep': 9, 'Oct':10, 'Nov': 11, 'Dec': 12}\n",
    "\n",
    "def parse_apache_time(s):\n",
    "    \"\"\" Convert Apache time format into a Python datetime object\n",
    "    Args:\n",
    "        s (str): date and time in Apache time format\n",
    "    Returns:\n",
    "        datetime: datetime object (ignore timezone for now)\n",
    "    \"\"\"\n",
    "    return datetime.datetime(int(s[7:11]),\n",
    "                             month_map[s[3:6]],\n",
    "                             int(s[0:2]),\n",
    "                             int(s[12:14]),\n",
    "                             int(s[15:17]),\n",
    "                             int(s[18:20]))\n",
    "\n",
    "\n",
    "def parseApacheLogLine(logline):\n",
    "    \"\"\" Parse a line in the Apache Common Log format\n",
    "    Args:\n",
    "        logline (str): a line of text in the Apache Common Log format\n",
    "    Returns:\n",
    "        tuple: either a dictionary containing the parts of the Apache Access Log and 1,\n",
    "               or the original invalid log line and 0\n",
    "    \"\"\"\n",
    "    match = re.search(APACHE_ACCESS_LOG_PATTERN, logline)\n",
    "    if match is None:\n",
    "        return (logline, 0)\n",
    "    size_field = match.group(9)\n",
    "    if size_field == '-':\n",
    "        size = long(0)\n",
    "    else:\n",
    "        size = long(match.group(9))\n",
    "    return (Row(\n",
    "        host          = match.group(1),\n",
    "        client_identd = match.group(2),\n",
    "        user_id       = match.group(3),\n",
    "        date_time     = parse_apache_time(match.group(4)),\n",
    "        method        = match.group(5),\n",
    "        endpoint      = match.group(6),\n",
    "        protocol      = match.group(7),\n",
    "        response_code = int(match.group(8)),\n",
    "        content_size  = size\n",
    "    ), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A regular expression pattern to extract fields from the log line\n",
    "APACHE_ACCESS_LOG_PATTERN = '^(\\S+) (\\S+) (\\S+) \\[([\\w:/]+\\s[+\\-]\\d{4})\\] \"(\\S+) (\\S+)\\s*(\\S*)\" (\\d{3}) (\\S+)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 建立RDD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseLogs(logFile):\n",
    "    \"\"\" Read and parse log file \"\"\"\n",
    "    parsed_logs = (sc\n",
    "                   .textFile(logFile)\n",
    "                   .map(parseApacheLogLine)\n",
    "                   .cache())\n",
    "\n",
    "    access_logs = (parsed_logs\n",
    "                   .filter(lambda s: s[1] == 1)\n",
    "                   .map(lambda s: s[0])\n",
    "                   .cache())\n",
    "\n",
    "    failed_logs = (parsed_logs\n",
    "                   .filter(lambda s: s[1] == 0)\n",
    "                   .map(lambda s: s[0]))\n",
    "    failed_logs_count = failed_logs.count()\n",
    "    \n",
    "    if failed_logs_count > 0:\n",
    "        print('Number of invalid logline: {}'.format(failed_logs.count()))\n",
    "        for line in failed_logs.take(20):\n",
    "            try:\n",
    "                print('Invalid logline: {}'.format(str(line)))\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    print('Read {} lines, successfully parsed {} lines, failed to parse {} lines'.format(parsed_logs.count(), access_logs.count(), failed_logs.count()))\n",
    "    return parsed_logs, access_logs, failed_logs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_logs, access_logs, failed_logs = parseLogs('hdfs:///tmp/NASA_access_log_Jul95')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 資料清洗\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 測試不同的 Log Pattern\n",
    "APACHE_ACCESS_LOG_PATTERN = '^(\\S+) (\\S+) (\\S+) \\[([\\w:/]+\\s[+\\-]\\d{4})\\] \"(\\S+) (\\S+)\\s*(\\S*)\\s*\" (\\d{3}) (\\S+)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_logs, access_logs, failed_logs = parseLogs('hdfs:///tmp/NASA_access_log_Jul95')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2:  Log 資料基本分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 內容大小統計\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistics based on the content size.\n",
    "content_sizes = access_logs.map(lambda log: log.content_size).cache()\n",
    "print('Content Size Avg: %i, Min: %i, Max: %s' % (\n",
    "    content_sizes.reduce(lambda a, b : a + b) / content_sizes.count(),\n",
    "    content_sizes.min(),\n",
    "    content_sizes.max()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Response Code 分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Response Code to Count\n",
    "responseCodeToCount = (access_logs\n",
    "                       .map(lambda log: (log.response_code, 1))\n",
    "                       .reduceByKey(lambda a, b : a + b)\n",
    "                       .cache())\n",
    "responseCodeToCountList = responseCodeToCount.take(100)\n",
    "print('Found %d response codes' % len(responseCodeToCountList))\n",
    "print('Response Code Counts: %s' % responseCodeToCountList)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 使用 Matplotlib 畫圖  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = responseCodeToCount.map(lambda (x, y): x).collect()\n",
    "print(labels)\n",
    "count = access_logs.count()\n",
    "fracs = responseCodeToCount.map(lambda (x, y): (float(y) / count)).collect()\n",
    "print(fracs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def pie_pct_format(value):\n",
    "    \"\"\" Determine the appropriate format string for the pie chart percentage label\n",
    "    Args:\n",
    "        value: value of the pie slice\n",
    "    Returns:\n",
    "        str: formated string label; if the slice is too small to fit, returns an empty string for label\n",
    "    \"\"\"\n",
    "    return '' if value < 7 else '%.0f%%' % value\n",
    "\n",
    "fig = plt.figure(figsize=(4.5, 4.5), facecolor='white', edgecolor='white')\n",
    "colors = ['yellowgreen', 'lightskyblue', 'gold', 'purple', 'lightcoral', 'yellow', 'black']\n",
    "explode = (0.05, 0.05, 0.1, 0, 0, 0, 0)\n",
    "patches, texts, autotexts = plt.pie(fracs, labels=labels, colors=colors,\n",
    "                                    explode=explode, autopct=pie_pct_format,\n",
    "                                    shadow=False,  startangle=125)\n",
    "for text, autotext in zip(texts, autotexts):\n",
    "    if autotext.get_text() == '':\n",
    "        text.set_text('')  # If the slice is small to fit, don't show a text label\n",
    "plt.legend(labels, loc=(0.80, -0.1), shadow=True)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Frequent Hosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hostCountPairTuple = access_logs.map(lambda log: (log.host, 1))\n",
    "\n",
    "hostSum = hostCountPairTuple.reduceByKey(lambda a, b : a + b)\n",
    "\n",
    "hostMoreThan10 = hostSum.filter(lambda s: s[1] > 10)\n",
    "\n",
    "hostsPick20 = (hostMoreThan10\n",
    "               .map(lambda s: s[0])\n",
    "               .take(20))\n",
    "\n",
    "print('Any 20 hosts that have accessed more then 10 times: %s' % hostsPick20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 將 Endpoints 視覺化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoints = (access_logs\n",
    "             .map(lambda log: (log.endpoint, 1))\n",
    "             .reduceByKey(lambda a, b : a + b)\n",
    "             .cache())\n",
    "ends = endpoints.map(lambda (x, y): x).collect()\n",
    "counts = endpoints.map(lambda (x, y): y).collect()\n",
    "\n",
    "fig = plt.figure(figsize=(8,4.2), facecolor='white', edgecolor='white')\n",
    "plt.axis([0, len(ends), 0, max(counts)])\n",
    "plt.grid(b=True, which='major', axis='y')\n",
    "plt.xlabel('Endpoints')\n",
    "plt.ylabel('Number of Hits')\n",
    "plt.plot(counts)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: 分析網站伺服器 Log "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Top Ten Error Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not200 = access_logs.filter(lambda log: log.response_code != 200)\n",
    "\n",
    "endpointCountPairTuple = not200.map(lambda log: (log.endpoint, 1))\n",
    "\n",
    "endpointSum = endpointCountPairTuple.reduceByKey(lambda a, b : a + b)\n",
    "\n",
    "topTenErrURLs = endpointSum.takeOrdered(10, lambda s: -1 * s[1])\n",
    "print('Top Ten failed URLs: %s' % topTenErrURLs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Number of Unique Hosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hosts = access_logs.map(lambda log: log.host)\n",
    "\n",
    "uniqueHosts = hosts.distinct()\n",
    "\n",
    "uniqueHostCount = uniqueHosts.count()\n",
    "print('Unique hosts: %d' % uniqueHostCount)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Number of Unique Daily Hosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dayToHostPairTuple = access_logs.map(lambda log: (log.date_time.day, log.host)).distinct()\n",
    "\n",
    "dayGroupedHosts = dayToHostPairTuple.groupByKey()\n",
    "\n",
    "dayHostCount = dayGroupedHosts.map(lambda (day, hosts): (day, len(hosts)))\n",
    "\n",
    "dailyHosts = (dayHostCount\n",
    "              .sortByKey()\n",
    "              .cache())\n",
    "dailyHostsList = dailyHosts.take(30)\n",
    "print('Unique hosts per day: %s' % dailyHostsList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Visualizing the Number of Unique Daily Hosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daysWithHosts = dailyHosts.map(lambda log: log[0]).collect()\n",
    "hosts = dailyHosts.map(lambda log: log[1]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,4.5), facecolor='white', edgecolor='white')\n",
    "plt.axis([min(daysWithHosts), max(daysWithHosts), 0, max(hosts)+500])\n",
    "plt.grid(b=True, which='major', axis='y')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Hosts')\n",
    "plt.plot(daysWithHosts, hosts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Average Number of Daily Requests per Hosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dayAndHostTuple = access_logs.map(lambda log: (log.date_time.day, log.host))\n",
    "\n",
    "groupedByDay = dayAndHostTuple.groupByKey()\n",
    "\n",
    "sortedByDay = groupedByDay.sortByKey()\n",
    "\n",
    "avgDailyReqPerHost = (sortedByDay\n",
    "                      .map(lambda(day, requests): (day, len(requests)))\n",
    "                      .join(dailyHosts)\n",
    "                     .map(lambda(day, (totalRequests, numOfHosts)): (day, totalRequests/numOfHosts))\n",
    "                     .sortByKey()\n",
    "                     .cache())\n",
    "avgDailyReqPerHostList = avgDailyReqPerHost.take(30)\n",
    "print('Average number of daily requests per Hosts is %s' % avgDailyReqPerHostList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Visualizing the Average Daily Requests per Unique Host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daysWithAvg = avgDailyReqPerHost.map(lambda (day, avg): day).collect()\n",
    "avgs = avgDailyReqPerHost.map(lambda (day, avg): avg).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,4.2), facecolor='white', edgecolor='white')\n",
    "plt.axis([0, max(daysWithAvg), 0, max(avgs)+2])\n",
    "plt.grid(b=True, which='major', axis='y')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Average')\n",
    "plt.plot(daysWithAvg, avgs)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
